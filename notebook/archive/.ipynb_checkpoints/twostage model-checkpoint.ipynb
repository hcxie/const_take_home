{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d817b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\operation d\\active project\\const_hw\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e724975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as imblearn_make_pipeline\n",
    "from src._helper_class import *\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, PoissonRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, average_precision_score\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197b7b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = pd.read_csv(\"data/dengue_features_train.csv\")\n",
    "train_label = pd.read_csv(\"data/dengue_labels_train.csv\")\n",
    "test_data = pd.read_csv(\"data/dengue_features_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b26538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "clf_scoring = 'average_precision'\n",
    "\n",
    "clf_pipeline = imblearn_make_pipeline(\n",
    "    Dengue_cat_encoder(),\n",
    "    Stationarity_adjustment(),\n",
    "    Feature_argumentation1(),\n",
    "    Standardization(),\n",
    "    Imputer(),\n",
    "    Feature_argumentation2(),\n",
    "    Feature_argumentation3(),\n",
    "    Feature_selection(cv_metric = clf_scoring,\n",
    "                      classify_mode = 1),\n",
    "    General_estimator()\n",
    ")\n",
    "\n",
    "clf_parameters = [\n",
    "    {\"general_estimator__estimator\": [XGBClassifier(grow_policy = \"lossguide\",\n",
    "                                                   objective = \"binary:logistic\",\n",
    "                                                   booster = \"gbtree\",\n",
    "                                                   tree_method = \"hist\",\n",
    "                                                   eta = 0.1\n",
    "                                                   )\n",
    "                                     ],\n",
    "     \"general_estimator__estimator__n_estimators\": [5],\n",
    "     \"general_estimator__estimator__scale_pos_weight\": [1],\n",
    "     \"general_estimator__estimator__max_leaves\": [7],\n",
    "     \"general_estimator__estimator__min_child_weight\": [1],\n",
    "     \"general_estimator__estimator__subsample\": [1],\n",
    "     \"feature_selection__estimator\": [XGBClassifier(objective = \"binary:logistic\",\n",
    "                                                   booster = \"gbtree\",\n",
    "                                                   tree_method = \"hist\")\n",
    "                                     ]\n",
    "    },\n",
    "    \n",
    "    {\"general_estimator__estimator\": [LogisticRegression()],\n",
    "     \"general_estimator__estimator__class_weight\": [\"balanced\"],\n",
    "     \"feature_selection__estimator\": [LogisticRegression()]\n",
    "    },\n",
    "    \n",
    "    {\"general_estimator__estimator\": [SVC(kernel = 'rbf',\n",
    "                                          max_iter = 10000)\n",
    "                                     ],\n",
    "     \"general_estimator__estimator__class_weight\": [\"balanced\"],\n",
    "     \"general_estimator__estimator__C\": [1], # [1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "     \"feature_selection__estimator\": [SVC(kernel = 'rbf',\n",
    "                                          max_iter = 10000)\n",
    "                                     ]\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# regression pipeline\n",
    "\n",
    "reg_scoring = \"neg_mean_absolute_error\"\n",
    "\n",
    "reg_pipeline = imblearn_make_pipeline(\n",
    "    Dengue_cat_encoder(),\n",
    "    Stationarity_adjustment(),\n",
    "    Feature_argumentation1(),\n",
    "    Standardization(),\n",
    "    Imputer(),\n",
    "    Feature_argumentation2(),\n",
    "    Feature_argumentation3(),\n",
    "    Feature_selection(),\n",
    "    General_estimator()\n",
    ")\n",
    "\n",
    "reg_parameters = [\n",
    "    {\"general_estimator__estimator\": [XGBRegressor(grow_policy = \"lossguide\",\n",
    "                                                   objective = \"reg:squarederror\",\n",
    "                                                   booster = \"gbtree\",\n",
    "                                                   tree_method = \"hist\",\n",
    "                                                   eta = 0.1\n",
    "                                                   )\n",
    "                                     ],\n",
    "     \"general_estimator__estimator__n_estimators\": [10],\n",
    "     \"general_estimator__estimator__max_leaves\": [5],\n",
    "     \"general_estimator__estimator__min_child_weight\": [1],\n",
    "     \"general_estimator__estimator__subsample\": [1],\n",
    "     \"general_estimator__severity_mode\": [1],\n",
    "     \"feature_selection__estimator\": [XGBRegressor(objective = \"reg:squarederror\",\n",
    "                                                   booster = \"gbtree\",\n",
    "                                                   tree_method = \"hist\"\n",
    "                                                   )\n",
    "                                     ]\n",
    "    },\n",
    "    \n",
    "    {\"general_estimator__estimator\": [PoissonRegressor(max_iter = 10000)],\n",
    "     \"general_estimator__estimator__alpha\": [0.1],\n",
    "     \"general_estimator__severity_mode\": [1],\n",
    "     \"feature_selection__estimator\": [PoissonRegressor(max_iter = 10000)]\n",
    "    },\n",
    "    \n",
    "    {\"general_estimator__estimator\": [SVR(kernel = 'rbf',\n",
    "                                          max_iter = 10000)\n",
    "                                     ],\n",
    "     \"general_estimator__estimator__C\": [1],\n",
    "     \"general_estimator__severity_mode\": [1],\n",
    "     \"feature_selection__estimator\": [SVR(kernel = 'rbf',\n",
    "                                          max_iter = 10000)\n",
    "                                     ]\n",
    "    }\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4b90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpensity_model_fit_transform(city, \n",
    "                                   threshold, \n",
    "                                   train_data, \n",
    "                                   train_label, \n",
    "                                   test_data, \n",
    "                                   model_scoring, \n",
    "                                   model_pipeline, \n",
    "                                   model_parameters):\n",
    "    \n",
    "    train_data = train_data.loc[train_data[\"city\"] == city,:].copy()\n",
    "    train_data.reset_index(drop = True, inplace = True)\n",
    "    X = train_data.drop(columns = [\"city\"])\n",
    "    \n",
    "    Y = train_label.loc[train_label[\"city\"] == city,:].copy()\n",
    "    Y.reset_index(drop = True, inplace = True)\n",
    "    Y = Y[\"total_cases\"]\n",
    "    Y = (Y >= threshold).astype(int)\n",
    "    \n",
    "    test_data = test_data.loc[test_data[\"city\"] == city,:].copy()\n",
    "    test_data.reset_index(drop = True, inplace = True)\n",
    "    X_test = test_data.drop(columns = [\"city\"])\n",
    "    \n",
    "    model_parameters[0][\"general_estimator__estimator__scale_pos_weight\"] = [len(Y)/Y.sum()]\n",
    "\n",
    "    model_gscv = GridSearchCV(estimator = model_pipeline, \n",
    "                              param_grid = model_parameters, \n",
    "                              scoring = model_scoring, \n",
    "                              cv = TimeSeriesSplit(n_splits = 3), \n",
    "                              verbose = 1,\n",
    "                              n_jobs = -1,\n",
    "                              return_train_score = True,\n",
    "                              error_score = 0)\n",
    "    \n",
    "    model_gscv.fit(X, Y)\n",
    "    \n",
    "    print(\"The select parameters:\")\n",
    "    print(model_gscv.best_params_)\n",
    "    \n",
    "    pred_train = model_gscv.best_estimator_.predict_proba(X)[:,1]\n",
    "    pred_test = model_gscv.best_estimator_.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print(\"current average precision: {}\".format(average_precision_score(Y, pred_train)))\n",
    "    \n",
    "    train_data[\"perpensity\"] = pred_train\n",
    "    test_data[\"perpensity\"] = pred_test\n",
    "    \n",
    "    return train_data[[\"city\", \"week_start_date\", \"perpensity\"]], test_data[[\"city\", \"week_start_date\", \"perpensity\"]], model_gscv\n",
    "\n",
    "def severity_model_fit_transform(city, \n",
    "                                 threshold, \n",
    "                                 train_data, \n",
    "                                 train_label, \n",
    "                                 test_data, \n",
    "                                 model_scoring, \n",
    "                                 model_pipeline, \n",
    "                                 model_parameters):\n",
    "    \n",
    "    train_data = train_data.loc[train_data[\"city\"] == city,:].copy()\n",
    "    train_data.reset_index(drop = True, inplace = True)\n",
    "    X = train_data.drop(columns = [\"city\"])\n",
    "    \n",
    "    Y = train_label.loc[train_label[\"city\"] == city,:].copy()\n",
    "    Y.reset_index(drop = True, inplace = True)\n",
    "    Y = Y[\"total_cases\"]\n",
    "    \n",
    "    test_data = test_data.loc[test_data[\"city\"] == city,:].copy()\n",
    "    test_data.reset_index(drop = True, inplace = True)\n",
    "    X_test = test_data.drop(columns = [\"city\"])\n",
    "    \n",
    "    for i in range(len(model_parameters)):\n",
    "        model_parameters[0][\"general_estimator__threshold\"] = [threshold]\n",
    "           \n",
    "    model_gscv = GridSearchCV(estimator = model_pipeline, \n",
    "                              param_grid = model_parameters, \n",
    "                              scoring = model_scoring, \n",
    "                              cv = TimeSeriesSplit(n_splits = 3), \n",
    "                              verbose = 1,\n",
    "                              n_jobs = -1,\n",
    "                              return_train_score = True,\n",
    "                              error_score = Y.mean()+ Y.std())\n",
    "    \n",
    "\n",
    "    \n",
    "    model_gscv.fit(X, Y)\n",
    "    \n",
    "    #print(\"The select parameters:\")\n",
    "    #print(model_gscv.best_params_)\n",
    "    \n",
    "    pred_train = model_gscv.best_estimator_.predict(X)\n",
    "    pred_test = model_gscv.best_estimator_.predict(X_test)\n",
    "        \n",
    "    train_data[\"severity\"] = pred_train\n",
    "    test_data[\"severity\"] = pred_test\n",
    "    \n",
    "    return train_data[[\"city\", \"week_start_date\", \"severity\"]], test_data[[\"city\", \"week_start_date\", \"severity\"]], model_gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733ca250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_stage_model_wraper(train_data, \n",
    "                           train_label, \n",
    "                           test_data, \n",
    "                           model_scoring_p, \n",
    "                           model_pipeline_p, \n",
    "                           model_parameters_p,\n",
    "                           model_scoring_s, \n",
    "                           model_pipeline_s, \n",
    "                           model_parameters_s):\n",
    "    best_score = np.inf\n",
    "    \n",
    "    threshold_list_sj = [60, 90, 100]\n",
    "    threshold_list_iq = [17, 20, 40]\n",
    "    \n",
    "    for threshold in threshold_list_sj:\n",
    "        print(threshold)\n",
    "        #print(\"fitting perpensity\")\n",
    "    \n",
    "        train_perpen_sj, test_perpen_sj, cv_perpen_sj = perpensity_model_fit_transform(\"sj\",\n",
    "                                                                              threshold,\n",
    "                                                                              train_data, \n",
    "                                                                              train_label, \n",
    "                                                                              test_data, \n",
    "                                                                              model_scoring_p,\n",
    "                                                                              model_pipeline_p,\n",
    "                                                                              model_parameters_p)\n",
    "        #print(\"fitting severity\")\n",
    "        train_sev_sj, test_sev_sj, cv_sev_sj = severity_model_fit_transform(\"sj\",\n",
    "                                                                            threshold,\n",
    "                                                                            train_data, \n",
    "                                                                            train_label, \n",
    "                                                                            test_data, \n",
    "                                                                            model_scoring_s,\n",
    "                                                                            model_pipeline_s,\n",
    "                                                                            model_parameters_s)\n",
    "\n",
    "    for threshold in threshold_list_iq:\n",
    "        print(threshold)\n",
    "        #print(\"fitting perpensity\")        \n",
    "        train_perpen_iq, test_perpen_iq, cv_perpen_iq = perpensity_model_fit_transform(\"iq\",\n",
    "                                                                              threshold,\n",
    "                                                                              train_data, \n",
    "                                                                              train_label, \n",
    "                                                                              test_data, \n",
    "                                                                              model_scoring_p,\n",
    "                                                                              model_pipeline_p,\n",
    "                                                                              model_parameters_p)\n",
    "    \n",
    "\n",
    "        #print(\"fitting severity\")\n",
    "        train_sev_iq, test_sev_iq, cv_sev_iq = severity_model_fit_transform(\"iq\",\n",
    "                                                                            threshold,\n",
    "                                                                            train_data, \n",
    "                                                                            train_label, \n",
    "                                                                            test_data, \n",
    "                                                                            model_scoring_s,\n",
    "                                                                            model_pipeline_s,\n",
    "                                                                            model_parameters_s)\n",
    "        #-----------------------------------------\n",
    "        temp_train_data = train_data.copy()\n",
    "    \n",
    "        train_perpen = pd.concat([train_perpen_sj, train_perpen_iq], ignore_index = True)\n",
    "        train_sev = pd.concat([train_sev_sj, train_sev_iq], ignore_index = True)\n",
    "                        \n",
    "        temp_train_data = temp_train_data.merge(train_perpen, on = [\"city\", \"week_start_date\"], how = \"left\")\n",
    "        temp_train_data = temp_train_data.merge(train_sev, on = [\"city\", \"week_start_date\"], how = \"left\")\n",
    "        \n",
    "        train_prediction = (temp_train_data[\"perpensity\"] * temp_train_data[\"severity\"]).to_numpy()\n",
    "        train_prediction = train_prediction - train_prediction.mean() + train_label[\"total_cases\"].mean()\n",
    "        \n",
    "        temp_train_data[\"prediction\"] = train_prediction.astype(int)\n",
    "        #----------------------------\n",
    "        temp_test_data = test_data.copy()\n",
    "        \n",
    "        test_perpen = pd.concat([test_perpen_sj, test_perpen_iq], ignore_index = True)\n",
    "        test_sev = pd.concat([test_sev_sj, test_sev_iq], ignore_index = True)\n",
    "    \n",
    "        temp_test_data = temp_test_data.merge(test_perpen, on = [\"city\", \"week_start_date\"], how = \"left\")\n",
    "        temp_test_data = temp_test_data.merge(test_sev, on = [\"city\", \"week_start_date\"], how = \"left\")\n",
    "\n",
    "        test_prediction = (temp_test_data[\"perpensity\"] * temp_test_data[\"severity\"]).to_numpy()\n",
    "        test_prediction = test_prediction - test_prediction.mean() + train_label[\"total_cases\"].mean()\n",
    "        \n",
    "        temp_test_data[\"prediction\"] = test_prediction.astype(int)\n",
    "    \n",
    "        current_score = mean_absolute_error(train_label[\"total_cases\"], temp_train_data[\"prediction\"])\n",
    "        \n",
    "        if current_score < best_score:\n",
    "            print(\"Perpensity selection threshold: {}\".format(threshold))\n",
    "            print(\"MAE: {}\".format(current_score))\n",
    "            out_train = temp_train_data\n",
    "            out_test = temp_test_data\n",
    "          \n",
    "    out_train = out_train[[\"city\", \"year\", \"weekofyear\", \"week_start_date\", \"prediction\"]]\n",
    "    out_test = out_test[[\"city\", \"year\", \"weekofyear\", \"week_start_date\", \"prediction\"]]\n",
    "    \n",
    "    return out_train, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b68a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "fitting perpensity\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=7, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=5, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 7, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 5, 'general_estimator__estimator__scale_pos_weight': 7.090909090909091, 'general_estimator__estimator__subsample': 1}\n",
      "current average precision: 0.4282608926550604\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 262, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 217, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 740, in fit\n",
      "    self.best_features = self._choose_best_features(X, y)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 708, in _choose_best_features\n",
      "    svm_columns_df = self._coef_feature_selection(svm_model, X, y)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 614, in _coef_feature_selection\n",
      "    model.fit(X, y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 199, in fit\n",
      "    y = self._validate_targets(y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 722, in _validate_targets\n",
      "    % len(cls)\n",
      "ValueError: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  category=UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:253: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=7, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=5, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 7, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 5, 'general_estimator__estimator__scale_pos_weight': 173.33333333333334, 'general_estimator__estimator__subsample': 1}\n",
      "current average precision: 0.5\n",
      "fitting severity\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=10, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 5, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 10, 'general_estimator__estimator__subsample': 1, 'general_estimator__severity_mode': 1, 'general_estimator__threshold': 60}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2 fits failed out of a total of 9.\n",
      "The score on these train-test partitions for these parameters will be set to 18.330862957593293.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 780, in fit\n",
      "    self.estimator.fit(subset_X, subset_Y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py\", line 255, in fit\n",
      "    multi_output=False,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 976, in check_X_y\n",
      "    estimator=estimator,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 808, in check_array\n",
      "    % (n_samples, array.shape, ensure_min_samples, context)\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 780, in fit\n",
      "    self.estimator.fit(subset_X, subset_Y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 196, in fit\n",
      "    accept_large_sparse=False,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 976, in check_X_y\n",
      "    estimator=estimator,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 808, in check_array\n",
      "    % (n_samples, array.shape, ensure_min_samples, context)\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:253: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  ConvergenceWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:253: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=10, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 5, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 10, 'general_estimator__estimator__subsample': 1, 'general_estimator__severity_mode': 1, 'general_estimator__threshold': 60}\n",
      "Perpensity selection threshold: 60\n",
      "MAE: 19.260302197802197\n",
      "90\n",
      "fitting perpensity\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  category=UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:253: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=7, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=5, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 7, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 5, 'general_estimator__estimator__scale_pos_weight': 15.344262295081966, 'general_estimator__estimator__subsample': 1}\n",
      "current average precision: 0.28525796115814667\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 262, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 217, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 740, in fit\n",
      "    self.best_features = self._choose_best_features(X, y)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 708, in _choose_best_features\n",
      "    svm_columns_df = self._coef_feature_selection(svm_model, X, y)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 614, in _coef_feature_selection\n",
      "    model.fit(X, y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 199, in fit\n",
      "    y = self._validate_targets(y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 722, in _validate_targets\n",
      "    % len(cls)\n",
      "ValueError: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  category=UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=7, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=5, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 7, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 5, 'general_estimator__estimator__scale_pos_weight': 520.0, 'general_estimator__estimator__subsample': 1}\n",
      "current average precision: 1.0\n",
      "fitting severity\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "The select parameters:\n",
      "{'feature_selection__estimator': SVR(max_iter=10000), 'general_estimator__estimator': SVR(C=1, max_iter=10000), 'general_estimator__estimator__C': 1, 'general_estimator__severity_mode': 1}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2 fits failed out of a total of 9.\n",
      "The score on these train-test partitions for these parameters will be set to 18.330862957593293.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 780, in fit\n",
      "    self.estimator.fit(subset_X, subset_Y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py\", line 255, in fit\n",
      "    multi_output=False,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 976, in check_X_y\n",
      "    estimator=estimator,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 808, in check_array\n",
      "    % (n_samples, array.shape, ensure_min_samples, context)\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 780, in fit\n",
      "    self.estimator.fit(subset_X, subset_Y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 196, in fit\n",
      "    accept_large_sparse=False,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 976, in check_X_y\n",
      "    estimator=estimator,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 808, in check_array\n",
      "    % (n_samples, array.shape, ensure_min_samples, context)\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:253: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  ConvergenceWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:253: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=10, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 5, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 10, 'general_estimator__estimator__subsample': 1, 'general_estimator__severity_mode': 1, 'general_estimator__threshold': 90}\n",
      "Perpensity selection threshold: 90\n",
      "MAE: 19.212225274725274\n",
      "100\n",
      "fitting perpensity\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=7, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=5, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 7, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 5, 'general_estimator__estimator__scale_pos_weight': 16.714285714285715, 'general_estimator__estimator__subsample': 1}\n",
      "current average precision: 0.3000836598931374\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 262, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 217, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 740, in fit\n",
      "    self.best_features = self._choose_best_features(X, y)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 708, in _choose_best_features\n",
      "    svm_columns_df = self._coef_feature_selection(svm_model, X, y)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 614, in _coef_feature_selection\n",
      "    model.fit(X, y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 199, in fit\n",
      "    y = self._validate_targets(y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 722, in _validate_targets\n",
      "    % len(cls)\n",
      "ValueError: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  category=UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 355, in _score\n",
      "    y_pred = method_caller(clf, \"decision_function\", X)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 372, in _score\n",
      "    y_pred = self._select_proba_binary(y_pred, clf.classes_)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 170, in _select_proba_binary\n",
      "    pos_label = self._kwargs.get(\"pos_label\", classes[1])\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "\n",
      "  UserWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=7, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=5, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 7, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 5, 'general_estimator__estimator__scale_pos_weight': 520.0, 'general_estimator__estimator__subsample': 1}\n",
      "current average precision: 1.0\n",
      "fitting severity\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "The select parameters:\n",
      "{'feature_selection__estimator': SVR(max_iter=10000), 'general_estimator__estimator': SVR(C=1, max_iter=10000), 'general_estimator__estimator__C': 1, 'general_estimator__severity_mode': 1}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2 fits failed out of a total of 9.\n",
      "The score on these train-test partitions for these parameters will be set to 18.330862957593293.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 780, in fit\n",
      "    self.estimator.fit(subset_X, subset_Y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py\", line 255, in fit\n",
      "    multi_output=False,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 976, in check_X_y\n",
      "    estimator=estimator,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 808, in check_array\n",
      "    % (n_samples, array.shape, ensure_min_samples, context)\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jb_dx\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"G:\\operation d\\active project\\const_hw\\src\\_helper_class.py\", line 780, in fit\n",
      "    self.estimator.fit(subset_X, subset_Y)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 196, in fit\n",
      "    accept_large_sparse=False,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 976, in check_X_y\n",
      "    estimator=estimator,\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 808, in check_array\n",
      "    % (n_samples, array.shape, ensure_min_samples, context)\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:253: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  ConvergenceWarning,\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:253: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The select parameters:\n",
      "{'feature_selection__estimator': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, reg_lambda=None, ...), 'general_estimator__estimator': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.1, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy='lossguide', importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=10, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, ...), 'general_estimator__estimator__max_leaves': 5, 'general_estimator__estimator__min_child_weight': 1, 'general_estimator__estimator__n_estimators': 10, 'general_estimator__estimator__subsample': 1, 'general_estimator__severity_mode': 1, 'general_estimator__threshold': 100}\n",
      "Perpensity selection threshold: 100\n",
      "MAE: 18.845467032967033\n"
     ]
    }
   ],
   "source": [
    "train_pred, test_pred = two_stage_model_wraper(train_data, \n",
    "                                               train_label, \n",
    "                                               test_data,\n",
    "                                               clf_scoring,\n",
    "                                               clf_pipeline,\n",
    "                                               clf_parameters,\n",
    "                                               reg_scoring, \n",
    "                                               reg_pipeline, \n",
    "                                               reg_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c22a751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_iq = train_label.loc[train_label[\"city\"]==\"iq\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49fdc686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pred[\"prediction\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b20377c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_label[\"total_cases\"].describ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd2bd6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    520.000000\n",
       "mean       7.565385\n",
       "std       10.765478\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        5.000000\n",
       "75%        9.000000\n",
       "max      116.000000\n",
       "Name: total_cases, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_iq[\"total_cases\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ed3679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explained_variance': make_scorer(explained_variance_score),\n",
       " 'r2': make_scorer(r2_score),\n",
       " 'max_error': make_scorer(max_error, greater_is_better=False),\n",
       " 'neg_median_absolute_error': make_scorer(median_absolute_error, greater_is_better=False),\n",
       " 'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False),\n",
       " 'neg_mean_absolute_percentage_error': make_scorer(mean_absolute_percentage_error, greater_is_better=False),\n",
       " 'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       " 'neg_mean_squared_log_error': make_scorer(mean_squared_log_error, greater_is_better=False),\n",
       " 'neg_root_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False, squared=False),\n",
       " 'neg_mean_poisson_deviance': make_scorer(mean_poisson_deviance, greater_is_better=False),\n",
       " 'neg_mean_gamma_deviance': make_scorer(mean_gamma_deviance, greater_is_better=False),\n",
       " 'accuracy': make_scorer(accuracy_score),\n",
       " 'top_k_accuracy': make_scorer(top_k_accuracy_score, needs_threshold=True),\n",
       " 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True),\n",
       " 'roc_auc_ovr': make_scorer(roc_auc_score, needs_proba=True, multi_class=ovr),\n",
       " 'roc_auc_ovo': make_scorer(roc_auc_score, needs_proba=True, multi_class=ovo),\n",
       " 'roc_auc_ovr_weighted': make_scorer(roc_auc_score, needs_proba=True, multi_class=ovr, average=weighted),\n",
       " 'roc_auc_ovo_weighted': make_scorer(roc_auc_score, needs_proba=True, multi_class=ovo, average=weighted),\n",
       " 'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
       " 'average_precision': make_scorer(average_precision_score, needs_threshold=True),\n",
       " 'neg_log_loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True),\n",
       " 'neg_brier_score': make_scorer(brier_score_loss, greater_is_better=False, needs_proba=True),\n",
       " 'adjusted_rand_score': make_scorer(adjusted_rand_score),\n",
       " 'rand_score': make_scorer(rand_score),\n",
       " 'homogeneity_score': make_scorer(homogeneity_score),\n",
       " 'completeness_score': make_scorer(completeness_score),\n",
       " 'v_measure_score': make_scorer(v_measure_score),\n",
       " 'mutual_info_score': make_scorer(mutual_info_score),\n",
       " 'adjusted_mutual_info_score': make_scorer(adjusted_mutual_info_score),\n",
       " 'normalized_mutual_info_score': make_scorer(normalized_mutual_info_score),\n",
       " 'fowlkes_mallows_score': make_scorer(fowlkes_mallows_score),\n",
       " 'precision': make_scorer(precision_score, average=binary),\n",
       " 'precision_macro': make_scorer(precision_score, pos_label=None, average=macro),\n",
       " 'precision_micro': make_scorer(precision_score, pos_label=None, average=micro),\n",
       " 'precision_samples': make_scorer(precision_score, pos_label=None, average=samples),\n",
       " 'precision_weighted': make_scorer(precision_score, pos_label=None, average=weighted),\n",
       " 'recall': make_scorer(recall_score, average=binary),\n",
       " 'recall_macro': make_scorer(recall_score, pos_label=None, average=macro),\n",
       " 'recall_micro': make_scorer(recall_score, pos_label=None, average=micro),\n",
       " 'recall_samples': make_scorer(recall_score, pos_label=None, average=samples),\n",
       " 'recall_weighted': make_scorer(recall_score, pos_label=None, average=weighted),\n",
       " 'f1': make_scorer(f1_score, average=binary),\n",
       " 'f1_macro': make_scorer(f1_score, pos_label=None, average=macro),\n",
       " 'f1_micro': make_scorer(f1_score, pos_label=None, average=micro),\n",
       " 'f1_samples': make_scorer(f1_score, pos_label=None, average=samples),\n",
       " 'f1_weighted': make_scorer(f1_score, pos_label=None, average=weighted),\n",
       " 'jaccard': make_scorer(jaccard_score, average=binary),\n",
       " 'jaccard_macro': make_scorer(jaccard_score, pos_label=None, average=macro),\n",
       " 'jaccard_micro': make_scorer(jaccard_score, pos_label=None, average=micro),\n",
       " 'jaccard_samples': make_scorer(jaccard_score, pos_label=None, average=samples),\n",
       " 'jaccard_weighted': make_scorer(jaccard_score, pos_label=None, average=weighted)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15397936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20+12+1+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d23ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
